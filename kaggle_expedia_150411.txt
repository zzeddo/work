제목 : 캐글 뽀개기
강사 : 김승욱(기상청 연구원)

데이터 분석을 위해서는 목적이 중요하다.
Target Setting이 중요하고, 하기 위한 역량을 키워서 수행해야 한다.
데이터 분석에서는 단계를 설정하여, 단계별로 진행해야 하면 한 단계가 끝나지 않았는데
다음 단계로 넘어가는 일이 없어야 한다.(빈 단계의 유추로 다음 단계가 엉망이 될 수 있다.)

1. Target Setting
2. Data Preparation
3. Data Exploration(Single Column, Double Columns, Multi Columns)
4. Model Building
5. Model Elaboration(평가) 
6. Model Verification(검증) -- Visualization

오늘의 주제는 Expedia라는 기업에서 kaggle사이트에 25,000$ 상금을 걸고
여행 서비스 판매 극대화할 수 있는 분석 모델 선정 작업한 것에 대하여 논의한다.

kaggle.com( The Home of Data Science) 사이트에 가입 필요
상금을 놓고 데이터 분석 대회를 열어 경쟁하고 있음
데이터 분석을 위한 유용한 정보가 나와 있음
30만명의 데이터 사이언티스트가 활동하고 있음.
교재 : https://drive.google.com/file/d/0B-2yw-flkAy_WWFJX0pDTGdmWEU/view?pli=1
실습데이터 : https://www.kaggle.com/c/expedia-personalized-sort/data?data.zip

오늘의 주제는 Expedia(Expedia.com)로 여행사가 고객들을 최대한 구매하게 만드는 방법에 대하여 공부하게 된다.
http://www.expedia.co.kr/ --> 스마트한 여행 익스피디아

다운 받은 expedia 데이터를 통하여 
Single Column을 통하여 분석하는 방법에 대하여 소개함
정규화된 데이터에 대한 컬럼수 N개에 따라 분석 방법은 N!가 될 수 있지만
분석가의 역량에 따라 수는 조정될 수 있다.

데이터와 산업에 따라 정확도에 대한 기준은 달라지며 전력산업의 경우 정확도가 98%이상이지만
예측이 잘못될 경우 원전 하나를 끄고 켜는 영향도가 있다.

ggplot의 다양한 기능 활용을 위하여 
docs.ggplot2.org/current 혹은 google 사이트에서 ggplot in R로 검색하면 다양한 정보 확인 가능

실습을 위한 데이터(train.csv)의 크기가 2.3G 되어 
R Studio에서 읽어 처리하는데 노트북 사용이 불가할 정도임
해결을 위하여 읽어 들이는 rows를 10만개로 제한하여 실습을 수행함
train = read.csv("D:/Work/data/train.csv", header = TRUE, nrows=100000) 

# 실습을 위해 필요한 도구
R (http://www.r-project.org/)
R Studio(http://www.rstudio.com/)
R에서 ggplot2 사용 필요하며, R 실행화면에서 "install.packages("ggplot2")" 수행하여 설치함


# 실습을 통하여 데이터 분석을 해 나가면서, 시사점과 개선 방안을 도출한다.
R Studio에서 "캐글뽀개기.R" 파일을 열어서 실행할 문장을 선택하여 CTRL-Enter로 스크립터를 수행한다.
예시>
memory.limit(size = 16000)
train = read.csv("D:/Work/data/train.csv", header = TRUE, nrows=100000) 
nrow(train)
head(train)
colnames(train)

####################
# 단일 column 분석 #
####################

# srch_id : 검색 아이디(search_id)
nrow(train)
length(unique(train$srch_id))
nrow(train) / length(unique(train$srch_id)) # id당 평균 노출상품 개수.. 약 25개..

# date_time : 검색한 시각
as.character(train$date_time[c(1, nrow(train))]) # as.character를 하지 않으면 factor연산이 엄청남.
date_data = data.frame(date = as.numeric(substr(gsub("-", "", train$date_time), 1, 8)))
head(date_data)
rownames(date_data) = NULL
date_data_2 = data.frame(date = sort(unique(date_data$date), decreasing = FALSE))
head(date_data_2, 3)
tail(date_data_2, 3)
nrow(date_data_2)
fix(date_data_2)
# 오호라.. 이건 8개월치 데이터임.

# 시점별 분포를 볼 것
date_data = data.frame(date = as.numeric(substr(gsub("-", "", train$date_time), 1, 8)))
date_data_table = data.frame(table(sort(date_data$date, decreasing = FALSE)))
date_data_table = transform( date_data_table, Var1 = as.numeric(as.character(date_data_table$Var1)))
# fix(date_data_table)
head(date_data_table)
plot(1:nrow(date_data_table), date_data_table$Freq, type = "l")
# 점의 분포를 볼 때 주중/주말 또는 요일에 따른 패턴이 있을 듯.


# site_id : 여러 expedia 사이트 번호 (30개 이상)
site_id = data.frame(table(train$site_id))
library("ggplot2")
ggplot(site_id, aes(x = 1:nrow(site_id), y = site_id$Freq)) + geom_point(size = 5)


마치면서 "마켓 3.0"을 시장의 변화를 알기 위하여 도움이 되며
"The R book"은 R을 전문적으로 사용할 경우 도움이 되며,
 R Graphics Cookbook을 통하여 데이터 시각화를 위한 좋은 참조 도서임
